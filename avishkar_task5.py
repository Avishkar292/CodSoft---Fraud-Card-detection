# -*- coding: utf-8 -*-
"""avishkar_Task5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ojrrp_4CNtM3rqNoo7qg82PVA74hWUap

FRAUD CARD DETECTION
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from imblearn.metrics import classification_report_imbalanced
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from sklearn.impute import SimpleImputer

# Load the dataset (replace 'your_dataset.csv' with your actual dataset)
data = pd.read_csv(r'/content/creditcard.csv')

# Explore the dataset and handle missing values
# For simplicity, let's use SimpleImputer to impute missing values with mean
imputer = SimpleImputer(strategy='mean')
data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)

# Separate features and target variable
X = data_imputed.drop('Class', axis=1)
y = data_imputed['Class']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the data using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Ensure the target variable is binary (0 and 1)
y_train_binary = (y_train == 1).astype(int)

# Handle class imbalance using oversampling (you can also try undersampling)
oversampler = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train_binary)

# Train a Random Forest Classifier (you can choose other classifiers like logistic regression)
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_resampled, y_train_resampled)


# Make predictions on the test set
y_pred = rf_model.predict(X_test)

# Convert y_test and y_pred to binary
y_test_binary = (y_test == 1).astype(int)
y_pred_binary = (y_pred == 1).astype(int)

# Evaluate the model's performance
precision = precision_score(y_test_binary, y_pred_binary)
recall = recall_score(y_test_binary, y_pred_binary)
f1 = f1_score(y_test_binary, y_pred_binary)
conf_matrix = confusion_matrix(y_test_binary, y_pred_binary)

print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')
print(f'Confusion Matrix:\n{conf_matrix}')

# Display imbalanced classification report
print('Imbalanced Classification Report:')
print(classification_report_imbalanced(y_test_binary, y_pred_binary))